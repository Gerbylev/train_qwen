{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0955001e-630b-48d6-8abf-4bd4f8073f51",
   "metadata": {},
   "source": [
    "# Обучаем Qwen\n",
    "\n",
    "## Установка зависимостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b6cac8a-96c2-453c-b6ca-5e85b8f323c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'LLaMA-Factory' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4bce442-591f-40e6-a6a7-64e3e0e7f62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping jax as it is not installed.\u001b[0m\u001b[33m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Obtaining file:///home/jupyter/workspace\n",
      "\u001b[31mERROR: file:///home/jupyter/workspace does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/jupyter/.local/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jupyter/.local/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.11/site-packages (0.27.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/jupyter/.local/lib/python3.11/site-packages (from huggingface_hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y jax\n",
    "!pip install -e .[bitsandbytes,liger-kernel]\n",
    "!pip install pandas\n",
    "!pip install huggingface_hub\n",
    "# Если в docker нету torch\n",
    "# !pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1\n",
    "# !pip install -e \".[torch,metrics]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a54319a3-c0e1-41c4-8280-885051547a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/workspace/LLaMA-Factory\n"
     ]
    }
   ],
   "source": [
    "%cd LLaMA-Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "518eca36-6a60-4158-9b9c-919c680373c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers<=4.46.1,>=4.41.2 in /home/jupyter/.local/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (4.46.1)\n",
      "Requirement already satisfied: datasets<=3.1.0,>=2.16.0 in /home/jupyter/.local/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (3.1.0)\n",
      "Requirement already satisfied: accelerate<=1.0.1,>=0.34.0 in /home/jupyter/.local/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: peft<=0.12.0,>=0.11.1 in /home/jupyter/.local/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (0.12.0)\n",
      "Requirement already satisfied: trl<=0.9.6,>=0.8.6 in /home/jupyter/.local/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (0.9.6)\n",
      "Requirement already satisfied: tokenizers<0.20.4,>=0.19.0 in /home/jupyter/.local/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (0.20.3)\n",
      "Requirement already satisfied: gradio<=5.12.0,>=4.38.0 in /home/jupyter/.local/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (4.44.1)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /home/jupyter/.local/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (2.2.3)\n",
      "Requirement already satisfied: scipy in /home/jupyter/.local/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (1.15.1)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (0.8.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (0.2.0)\n",
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (0.7.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (5.29.3)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (0.34.0)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (2.10.5)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (0.115.6)\n",
      "Requirement already satisfied: sse-starlette in /home/jupyter/.local/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (2.2.1)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /home/jupyter/.local/lib/python3.11/site-packages (from -r requirements.txt (line 18)) (3.10.0)\n",
      "Requirement already satisfied: fire in /home/jupyter/.local/lib/python3.11/site-packages (from -r requirements.txt (line 19)) (0.7.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 20)) (24.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 21)) (6.0.2)\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.11/site-packages (from -r requirements.txt (line 22)) (1.26.4)\n",
      "Requirement already satisfied: av in /home/jupyter/.local/lib/python3.11/site-packages (from -r requirements.txt (line 23)) (14.0.1)\n",
      "Requirement already satisfied: tyro<0.9.0 in /home/jupyter/.local/lib/python3.11/site-packages (from -r requirements.txt (line 24)) (0.8.14)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.11/site-packages (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (0.27.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.11/site-packages (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/jupyter/.local/lib/python3.11/site-packages (from datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/jupyter/.local/lib/python3.11/site-packages (from datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /home/jupyter/.local/lib/python3.11/site-packages (from datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/jupyter/.local/lib/python3.11/site-packages (from datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/jupyter/.local/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (3.11.11)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (6.1.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (2.5.1+cu124)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (4.8.0)\n",
      "Requirement already satisfied: ffmpy in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (0.28.1)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (6.4.5)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (3.10.15)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (10.4.0)\n",
      "Requirement already satisfied: pydub in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (0.9.3)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (2.2.3)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio-client==1.3.0->gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.0.0->-r requirements.txt (line 8)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.0.0->-r requirements.txt (line 8)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jupyter/.local/lib/python3.11/site-packages (from pandas>=2.0.0->-r requirements.txt (line 8)) (2025.1)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.11/site-packages (from uvicorn->-r requirements.txt (line 14)) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.11/site-packages (from uvicorn->-r requirements.txt (line 14)) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic->-r requirements.txt (line 15)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.11/site-packages (from pydantic->-r requirements.txt (line 15)) (2.27.2)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /opt/conda/lib/python3.11/site-packages (from fastapi->-r requirements.txt (line 16)) (0.41.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jupyter/.local/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 18)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jupyter/.local/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 18)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jupyter/.local/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 18)) (4.55.6)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/jupyter/.local/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 18)) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/jupyter/.local/lib/python3.11/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 18)) (3.2.1)\n",
      "Requirement already satisfied: termcolor in /home/jupyter/.local/lib/python3.11/site-packages (from fire->-r requirements.txt (line 19)) (2.5.0)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /home/jupyter/.local/lib/python3.11/site-packages (from tyro<0.9.0->-r requirements.txt (line 24)) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.11/site-packages (from tyro<0.9.0->-r requirements.txt (line 24)) (13.9.4)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/jupyter/.local/lib/python3.11/site-packages (from tyro<0.9.0->-r requirements.txt (line 24)) (1.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->-r requirements.txt (line 2)) (1.18.3)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx>=0.24.1->gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx>=0.24.1->gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (1.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 8)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers<=4.46.1,>=4.41.2->-r requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1.0->tyro<0.9.0->-r requirements.txt (line 24)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1.0->tyro<0.9.0->-r requirements.txt (line 24)) (2.18.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/jupyter/.local/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio<=5.12.0,>=4.38.0->-r requirements.txt (line 7)) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro<0.9.0->-r requirements.txt (line 24)) (0.1.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: llamafactory in /home/jupyter/.local/lib/python3.11/site-packages (0.9.1)\n",
      "Requirement already satisfied: transformers<=4.46.1,>=4.41.2 in /home/jupyter/.local/lib/python3.11/site-packages (from llamafactory) (4.46.1)\n",
      "Requirement already satisfied: datasets<=3.1.0,>=2.16.0 in /home/jupyter/.local/lib/python3.11/site-packages (from llamafactory) (3.1.0)\n",
      "Requirement already satisfied: accelerate<=1.0.1,>=0.34.0 in /home/jupyter/.local/lib/python3.11/site-packages (from llamafactory) (1.0.1)\n",
      "Requirement already satisfied: peft<=0.12.0,>=0.11.1 in /home/jupyter/.local/lib/python3.11/site-packages (from llamafactory) (0.12.0)\n",
      "Requirement already satisfied: trl<=0.9.6,>=0.8.6 in /home/jupyter/.local/lib/python3.11/site-packages (from llamafactory) (0.9.6)\n",
      "Requirement already satisfied: gradio<5.0.0,>=4.0.0 in /home/jupyter/.local/lib/python3.11/site-packages (from llamafactory) (4.44.1)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /home/jupyter/.local/lib/python3.11/site-packages (from llamafactory) (2.2.3)\n",
      "Requirement already satisfied: scipy in /home/jupyter/.local/lib/python3.11/site-packages (from llamafactory) (1.15.1)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.11/site-packages (from llamafactory) (0.8.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.11/site-packages (from llamafactory) (0.2.0)\n",
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.11/site-packages (from llamafactory) (0.7.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.11/site-packages (from llamafactory) (5.29.3)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.11/site-packages (from llamafactory) (0.34.0)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.11/site-packages (from llamafactory) (2.10.5)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.11/site-packages (from llamafactory) (0.115.6)\n",
      "Requirement already satisfied: sse-starlette in /home/jupyter/.local/lib/python3.11/site-packages (from llamafactory) (2.2.1)\n",
      "Requirement already satisfied: matplotlib>=3.7.0 in /home/jupyter/.local/lib/python3.11/site-packages (from llamafactory) (3.10.0)\n",
      "Requirement already satisfied: fire in /home/jupyter/.local/lib/python3.11/site-packages (from llamafactory) (0.7.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from llamafactory) (24.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from llamafactory) (6.0.2)\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.11/site-packages (from llamafactory) (1.26.4)\n",
      "Requirement already satisfied: av in /home/jupyter/.local/lib/python3.11/site-packages (from llamafactory) (14.0.1)\n",
      "Requirement already satisfied: tyro<0.9.0 in /home/jupyter/.local/lib/python3.11/site-packages (from llamafactory) (0.8.14)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate<=1.0.1,>=0.34.0->llamafactory) (6.1.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from accelerate<=1.0.1,>=0.34.0->llamafactory) (2.5.1+cu124)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate<=1.0.1,>=0.34.0->llamafactory) (0.27.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate<=1.0.1,>=0.34.0->llamafactory) (0.5.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets<=3.1.0,>=2.16.0->llamafactory) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/jupyter/.local/lib/python3.11/site-packages (from datasets<=3.1.0,>=2.16.0->llamafactory) (19.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/jupyter/.local/lib/python3.11/site-packages (from datasets<=3.1.0,>=2.16.0->llamafactory) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.11/site-packages (from datasets<=3.1.0,>=2.16.0->llamafactory) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.11/site-packages (from datasets<=3.1.0,>=2.16.0->llamafactory) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /home/jupyter/.local/lib/python3.11/site-packages (from datasets<=3.1.0,>=2.16.0->llamafactory) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/jupyter/.local/lib/python3.11/site-packages (from datasets<=3.1.0,>=2.16.0->llamafactory) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/jupyter/.local/lib/python3.11/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets<=3.1.0,>=2.16.0->llamafactory) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.11/site-packages (from datasets<=3.1.0,>=2.16.0->llamafactory) (3.11.11)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (4.8.0)\n",
      "Requirement already satisfied: ffmpy in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.3.0 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (1.3.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (0.28.1)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (6.4.5)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (3.10.15)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (10.4.0)\n",
      "Requirement already satisfied: pydub in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (0.9.3)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (4.12.2)\n",
      "Requirement already satisfied: urllib3~=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio<5.0.0,>=4.0.0->llamafactory) (2.2.3)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in /home/jupyter/.local/lib/python3.11/site-packages (from gradio-client==1.3.0->gradio<5.0.0,>=4.0.0->llamafactory) (12.0)\n",
      "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /opt/conda/lib/python3.11/site-packages (from fastapi->llamafactory) (0.41.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jupyter/.local/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jupyter/.local/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jupyter/.local/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory) (4.55.6)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/jupyter/.local/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/jupyter/.local/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib>=3.7.0->llamafactory) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=2.0.0->llamafactory) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jupyter/.local/lib/python3.11/site-packages (from pandas>=2.0.0->llamafactory) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic->llamafactory) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/conda/lib/python3.11/site-packages (from pydantic->llamafactory) (2.27.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers<=4.46.1,>=4.41.2->llamafactory) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/jupyter/.local/lib/python3.11/site-packages (from transformers<=4.46.1,>=4.41.2->llamafactory) (0.20.3)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /home/jupyter/.local/lib/python3.11/site-packages (from tyro<0.9.0->llamafactory) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.11/site-packages (from tyro<0.9.0->llamafactory) (13.9.4)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /home/jupyter/.local/lib/python3.11/site-packages (from tyro<0.9.0->llamafactory) (1.7.1)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.11/site-packages (from uvicorn->llamafactory) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.11/site-packages (from uvicorn->llamafactory) (0.14.0)\n",
      "Requirement already satisfied: termcolor in /home/jupyter/.local/lib/python3.11/site-packages (from fire->llamafactory) (2.5.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0->llamafactory) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio<5.0.0,>=4.0.0->llamafactory) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->llamafactory) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->llamafactory) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->llamafactory) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->llamafactory) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->llamafactory) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->llamafactory) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp->datasets<=3.1.0,>=2.16.0->llamafactory) (1.18.3)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx>=0.24.1->gradio<5.0.0,>=4.0.0->llamafactory) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx>=0.24.1->gradio<5.0.0,>=4.0.0->llamafactory) (1.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->llamafactory) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets<=3.1.0,>=2.16.0->llamafactory) (3.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory) (2.18.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->llamafactory) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->llamafactory) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->llamafactory) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->llamafactory) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->llamafactory) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->llamafactory) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->llamafactory) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->llamafactory) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->llamafactory) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->llamafactory) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->llamafactory) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->llamafactory) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->llamafactory) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->llamafactory) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->llamafactory) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate<=1.0.1,>=0.34.0->llamafactory) (1.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/jupyter/.local/lib/python3.11/site-packages (from typer<1.0,>=0.12->gradio<5.0.0,>=4.0.0->llamafactory) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro<0.9.0->llamafactory) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install llamafactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f84af6e9-f3f4-403a-bed1-8a4623b895cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/workspace\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22470aff-c2a7-4d92-9495-5b582d634584",
   "metadata": {},
   "source": [
    "Проверяем что нам доступен torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "811cbe4f-9373-48f4-abb7-4d3bfa035348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "try:\n",
    "  assert torch.cuda.is_available() is True\n",
    "except AssertionError:\n",
    "  print(\"Please set up a GPU before using LLaMA Factory: https://medium.com/mlearning-ai/training-yolov4-on-google-colab-316f8fff99c6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6f7fd-eda0-4bbd-a882-3a529289e429",
   "metadata": {},
   "source": [
    "## Поменять при необходимости\n",
    "\n",
    "Указываем модель и для какой задачи будет использоваться\n",
    "\n",
    "**task_description должен совпадать с названием датасета**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb66c628-c61e-4e4a-a7cc-514f356d67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"Qwen/Qwen2.5-7B-Instruct\"\n",
    "task_description = \"matching\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e44de9-1163-479c-a38f-6cebc4d600e2",
   "metadata": {},
   "source": [
    "## Устанавливаем модель\n",
    "\n",
    "Обязательно делаем это тут, а не в LLaMA Factory, так как там это синхроно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9f0ff2f-69a2-49ce-be0a-66e223b4fbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d418b75af0749b8ba198eb0243cf225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 14 files:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeb11094a3e1493fb34dea878ca001f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5665b7d95844ee5bef336c61e582655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96165f3c21648449d019608a2236709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "LICENSE:   0%|          | 0.00/11.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b4c8f7d27f4503b274ac17bacf7bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e388c0d846f548d7a942d3f48b014595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/6.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c2f6b61b57464ba5156cc177bebd6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184b5dbf9b2543249a896e7743f05299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4642908a23074058bd323a9ac6fd56b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951ef472bc344ab586f51f1509dc5f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a5d7611213432f978e9ae929917f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e37848c3e84276a51fc2e5b5c54eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/27.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7204755151ad4c0b8725f7c07339a6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc84530fafda425ea309ce8af07642d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ffdf0bb061495a88ac92569eeb7a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login, snapshot_download\n",
    "\n",
    "login(\"hf_token\")\n",
    "\n",
    "snapshot_download(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1741b53-cc1d-499e-aa40-1ec23e2ad1da",
   "metadata": {},
   "source": [
    "Папка для сохранения результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73670518-79db-45f8-9dce-0c39fa84e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "output_dir = f'./lora/{model}/{task_description}/train_{timestamp}'\n",
    "# os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093bf7c3-a22f-456a-8c3a-26ec0c7e2f31",
   "metadata": {},
   "source": [
    "## Запускаем обучение\n",
    "\n",
    "Меняем на нужные параметры запускаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a76bd1b5-a68d-477f-a332-0f4c2392826f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
      "0it [00:00, ?it/s]\n",
      "[INFO|2025-01-25 10:10:41] llamafactory.hparams.parser:355 >> Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.bfloat16\n",
      "[INFO|configuration_utils.py:679] 2025-01-25 10:10:41,731 >> loading configuration file config.json from cache at /home/jupyter/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/config.json\n",
      "[INFO|configuration_utils.py:746] 2025-01-25 10:10:41,738 >> Model config Qwen2Config {\n",
      "  \"_name_or_path\": \"Qwen/Qwen2.5-7B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3584,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 18944,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 28,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 152064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-25 10:10:42,146 >> loading file vocab.json from cache at /home/jupyter/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/vocab.json\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-25 10:10:42,146 >> loading file merges.txt from cache at /home/jupyter/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/merges.txt\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-25 10:10:42,146 >> loading file tokenizer.json from cache at /home/jupyter/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-25 10:10:42,146 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-25 10:10:42,146 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-25 10:10:42,146 >> loading file tokenizer_config.json from cache at /home/jupyter/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2475] 2025-01-25 10:10:42,345 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|configuration_utils.py:679] 2025-01-25 10:10:42,956 >> loading configuration file config.json from cache at /home/jupyter/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/config.json\n",
      "[INFO|configuration_utils.py:746] 2025-01-25 10:10:42,957 >> Model config Qwen2Config {\n",
      "  \"_name_or_path\": \"Qwen/Qwen2.5-7B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3584,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 18944,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 28,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 152064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-25 10:10:43,083 >> loading file vocab.json from cache at /home/jupyter/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/vocab.json\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-25 10:10:43,083 >> loading file merges.txt from cache at /home/jupyter/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/merges.txt\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-25 10:10:43,083 >> loading file tokenizer.json from cache at /home/jupyter/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-25 10:10:43,083 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-25 10:10:43,083 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:2211] 2025-01-25 10:10:43,083 >> loading file tokenizer_config.json from cache at /home/jupyter/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2475] 2025-01-25 10:10:43,282 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[INFO|2025-01-25 10:10:43] llamafactory.data.template:157 >> Replace eos token: <|im_end|>\n",
      "[INFO|2025-01-25 10:10:43] llamafactory.data.loader:157 >> Loading dataset /home/jupyter/workspace/data/matching/data_2025-01-25 10:04:17.json...\n",
      "Generating train split: 8974 examples [00:00, 49228.26 examples/s]\n",
      "num_proc must be <= 10. Reducing num_proc to 10 for dataset of size 10.\n",
      "Converting format of dataset (num_proc=10): 100%|█| 10/10 [00:00<00:00, 47.85 ex\n",
      "num_proc must be <= 10. Reducing num_proc to 10 for dataset of size 10.\n",
      "Running tokenizer on dataset (num_proc=10): 100%|█| 10/10 [00:01<00:00,  7.49 ex\n",
      "training example:\n",
      "input_ids:\n",
      "[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 33995, 4552, 1959, 29292, 1456, 54908, 33513, 58213, 48807, 133789, 7587, 10813, 5474, 60290, 133771, 1478, 1959, 5409, 28156, 24276, 17753, 17787, 5063, 19645, 1802, 56086, 5805, 128104, 52571, 13073, 58213, 48807, 35252, 272, 5063, 19645, 1802, 70729, 63780, 5805, 56825, 81841, 83098, 17686, 67274, 14144, 74181, 382, 20195, 68138, 73712, 1478, 19849, 58213, 48807, 16748, 510, 16, 13, 134922, 58821, 132529, 128692, 29380, 14191, 794, 52370, 15082, 24, 16, 24, 7123, 198, 17, 13, 38803, 98314, 141967, 3038, 137716, 65286, 34623, 13073, 25460, 47345, 28371, 52571, 18437, 220, 16, 17, 20, 10474, 16, 15, 134774, 12072, 49, 1867, 220, 18, 20, 20, 20, 18, 1022, 16854, 19645, 1802, 56086, 5805, 56825, 81841, 83098, 20264, 17686, 67274, 14144, 74181, 510, 16, 13, 794, 52370, 15082, 24, 16, 24, 7123, 134922, 58821, 132529, 128692, 29380, 14191, 198, 17, 13, 12072, 49, 1867, 38803, 98314, 141967, 3038, 137716, 13073, 25460, 47345, 28371, 52571, 220, 16, 17, 20, 87, 16, 15, 6442, 6442, 18437, 27499, 55091, 33504, 127541, 130794, 220, 18, 20, 20, 20, 18, 1406, 19311, 28156, 24276, 17753, 4824, 5063, 19645, 1802, 56086, 7587, 63262, 22621, 98200, 5805, 49845, 12228, 53161, 7972, 1504, 510, 27, 307, 62, 1792, 56973, 1478, 29, 1464, 366, 307, 62, 8005, 42975, 127662, 1339, 16206, 92647, 1504, 129348, 12281, 13502, 37421, 137470, 73626, 141615, 38003, 481, 73934, 1478, 5063, 19645, 1802, 130716, 7587, 143119, 1464, 13, 128544, 129856, 29380, 129258, 134212, 66645, 43116, 92508, 125947, 32642, 13, 151645, 198, 151644, 77091, 198, 16, 1464, 220, 16, 198, 17, 1464, 220, 17, 151645]\n",
      "inputs:\n",
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Ты — строительный закупщик и твоя задача — сопоставить позиции в заявке на закупку c позициями в предложении поставщика.\n",
      "\n",
      "Название товара для закупки:\n",
      "1. Полировальная машина Sturm AG919CP\n",
      "2. Диск войлочный серый на липучке Normal 125х10 мм SKRAB 35553\n",
      "\n",
      "\n",
      "\n",
      "Позиции в предложении от поставщика:\n",
      "1. Sturm AG919CP Полировальная машина\n",
      "2. SKRAB Диск войлочный на липучке 125x10мм Normal СЕРЫЙ 35553\n",
      "\n",
      "\n",
      "Сопоставь позиции и верни результат в таком формате:\n",
      "<id_товара> -> <id_предложения>\n",
      "\n",
      "В ответе могут присутствовать только цифры - номера позиций и знак ->. Не пиши больше никаких комментариев.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "1 -> 1\n",
      "2 -> 2<|im_end|>\n",
      "label_ids:\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 16, 1464, 220, 16, 198, 17, 1464, 220, 17, 151645]\n",
      "labels:\n",
      "1 -> 1\n",
      "2 -> 2<|im_end|>\n",
      "[INFO|configuration_utils.py:679] 2025-01-25 10:10:46,042 >> loading configuration file config.json from cache at /home/jupyter/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/config.json\n",
      "[INFO|configuration_utils.py:746] 2025-01-25 10:10:46,043 >> Model config Qwen2Config {\n",
      "  \"_name_or_path\": \"Qwen/Qwen2.5-7B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3584,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 18944,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 28,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 152064\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3937] 2025-01-25 10:10:46,364 >> loading weights file model.safetensors from cache at /home/jupyter/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1670] 2025-01-25 10:10:46,365 >> Instantiating Qwen2ForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|configuration_utils.py:1096] 2025-01-25 10:10:46,367 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645\n",
      "}\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:03<00:00,  1.07it/s]\n",
      "[INFO|modeling_utils.py:4800] 2025-01-25 10:10:50,141 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:4808] 2025-01-25 10:10:50,141 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2.5-7B-Instruct.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:1051] 2025-01-25 10:10:51,123 >> loading configuration file generation_config.json from cache at /home/jupyter/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/generation_config.json\n",
      "[INFO|configuration_utils.py:1096] 2025-01-25 10:10:51,123 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": [\n",
      "    151645,\n",
      "    151643\n",
      "  ],\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"repetition_penalty\": 1.05,\n",
      "  \"temperature\": 0.7,\n",
      "  \"top_k\": 20,\n",
      "  \"top_p\": 0.8\n",
      "}\n",
      "\n",
      "[INFO|2025-01-25 10:10:51] llamafactory.model.model_utils.checkpointing:157 >> Gradient checkpointing enabled.\n",
      "[INFO|2025-01-25 10:10:51] llamafactory.model.model_utils.attention:157 >> Using torch SDPA for faster training and inference.\n",
      "[INFO|2025-01-25 10:10:51] llamafactory.model.adapter:157 >> Upcasting trainable params to float32.\n",
      "[INFO|2025-01-25 10:10:51] llamafactory.model.adapter:157 >> Fine-tuning method: LoRA\n",
      "[INFO|2025-01-25 10:10:51] llamafactory.model.model_utils.misc:157 >> Found linear modules: v_proj,up_proj,q_proj,o_proj,gate_proj,down_proj,k_proj\n",
      "[INFO|2025-01-25 10:10:52] llamafactory.model.loader:157 >> trainable params: 20,185,088 || all params: 7,635,801,600 || trainable%: 0.2643\n",
      "/home/jupyter/.local/lib/python3.11/site-packages/llamafactory/train/sft/trainer.py:54: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomSeq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(**kwargs)\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "[INFO|trainer.py:698] 2025-01-25 10:10:52,817 >> Using auto half precision backend\n",
      "[INFO|trainer.py:2313] 2025-01-25 10:10:53,037 >> ***** Running training *****\n",
      "[INFO|trainer.py:2314] 2025-01-25 10:10:53,037 >>   Num examples = 10\n",
      "[INFO|trainer.py:2315] 2025-01-25 10:10:53,037 >>   Num Epochs = 3\n",
      "[INFO|trainer.py:2316] 2025-01-25 10:10:53,037 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:2319] 2025-01-25 10:10:53,037 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:2320] 2025-01-25 10:10:53,037 >>   Gradient Accumulation steps = 8\n",
      "[INFO|trainer.py:2321] 2025-01-25 10:10:53,037 >>   Total optimization steps = 3\n",
      "[INFO|trainer.py:2322] 2025-01-25 10:10:53,039 >>   Number of trainable parameters = 20,185,088\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:17<00:00,  5.87s/it][INFO|trainer.py:3801] 2025-01-25 10:11:10,164 >> Saving model checkpoint to ./lora/Qwen/Qwen2.5-7B-Instruct/matching/train_2025-01-25-10:10:36/checkpoint-3\n",
      "[INFO|configuration_utils.py:679] 2025-01-25 10:11:10,483 >> loading configuration file config.json from cache at /home/jupyter/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/config.json\n",
      "[INFO|configuration_utils.py:746] 2025-01-25 10:11:10,484 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3584,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 18944,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 28,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 152064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2646] 2025-01-25 10:11:10,573 >> tokenizer config file saved in ./lora/Qwen/Qwen2.5-7B-Instruct/matching/train_2025-01-25-10:10:36/checkpoint-3/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2025-01-25 10:11:10,573 >> Special tokens file saved in ./lora/Qwen/Qwen2.5-7B-Instruct/matching/train_2025-01-25-10:10:36/checkpoint-3/special_tokens_map.json\n",
      "[INFO|trainer.py:2584] 2025-01-25 10:11:10,881 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 17.8424, 'train_samples_per_second': 1.681, 'train_steps_per_second': 0.168, 'train_loss': 1.747917652130127, 'epoch': 2.4}\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:17<00:00,  5.95s/it]\n",
      "[INFO|trainer.py:3801] 2025-01-25 10:11:10,903 >> Saving model checkpoint to ./lora/Qwen/Qwen2.5-7B-Instruct/matching/train_2025-01-25-10:10:36\n",
      "[INFO|configuration_utils.py:679] 2025-01-25 10:11:11,193 >> loading configuration file config.json from cache at /home/jupyter/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/config.json\n",
      "[INFO|configuration_utils.py:746] 2025-01-25 10:11:11,195 >> Model config Qwen2Config {\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3584,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 18944,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 28,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 28,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 152064\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:2646] 2025-01-25 10:11:11,341 >> tokenizer config file saved in ./lora/Qwen/Qwen2.5-7B-Instruct/matching/train_2025-01-25-10:10:36/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2655] 2025-01-25 10:11:11,341 >> Special tokens file saved in ./lora/Qwen/Qwen2.5-7B-Instruct/matching/train_2025-01-25-10:10:36/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        2.4\n",
      "  total_flos               =   600050GF\n",
      "  train_loss               =     1.7479\n",
      "  train_runtime            = 0:00:17.84\n",
      "  train_samples_per_second =      1.681\n",
      "  train_steps_per_second   =      0.168\n",
      "[WARNING|2025-01-25 10:11:11] llamafactory.extras.ploting:162 >> No metric loss to plot.\n",
      "[WARNING|2025-01-25 10:11:11] llamafactory.extras.ploting:162 >> No metric eval_loss to plot.\n",
      "[WARNING|2025-01-25 10:11:11] llamafactory.extras.ploting:162 >> No metric eval_accuracy to plot.\n",
      "[INFO|modelcard.py:449] 2025-01-25 10:11:11,531 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
     ]
    }
   ],
   "source": [
    "step = 10\n",
    "batch_size = 1\n",
    "max_prompt_size = 10000\n",
    "lora_rank = 8\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0\n",
    "save_steps = 5000\n",
    "\n",
    "\n",
    "command = f\"\"\"\n",
    "llamafactory-cli train \\\n",
    "    --stage sft \\\n",
    "    --do_train True \\\n",
    "    --model_name_or_path {model} \\\n",
    "    --preprocessing_num_workers 16 \\\n",
    "    --finetuning_type lora \\\n",
    "    --template qwen \\\n",
    "    --flash_attn auto \\\n",
    "    --dataset_dir ./ \\\n",
    "    --dataset {task_description} \\\n",
    "    --cutoff_len {max_prompt_size} \\\n",
    "    --learning_rate 5e-05 \\\n",
    "    --num_train_epochs 3.0 \\\n",
    "    --max_samples {step} \\\n",
    "    --per_device_train_batch_size {batch_size} \\\n",
    "    --gradient_accumulation_steps 8 \\\n",
    "    --lr_scheduler_type cosine \\\n",
    "    --max_grad_norm 1.0 \\\n",
    "    --logging_steps 5 \\\n",
    "    --save_steps {save_steps} \\\n",
    "    --warmup_steps 0 \\\n",
    "    --packing False \\\n",
    "    --report_to none \\\n",
    "    --output_dir {output_dir} \\\n",
    "    --bf16 True \\\n",
    "    --plot_loss True \\\n",
    "    --ddp_timeout 180000000 \\\n",
    "    --optim adamw_torch \\\n",
    "    --lora_rank {lora_rank} \\\n",
    "    --lora_alpha {lora_alpha} \\\n",
    "    --lora_dropout {lora_dropout} \\\n",
    "    --lora_target all\n",
    "\"\"\"\n",
    "\n",
    "# Выполняем команду\n",
    "get_ipython().system(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b86e8-32b2-47dc-bcc3-a6f68986d34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!GRADIO_SHARE=1 llamafactory-cli webui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
